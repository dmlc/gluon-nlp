Catalog for GluonNLP
====================




Language Model
--------------
https://gluon-nlp.mxnet.io/model_zoo/language_model/index.html



Dataset: Wikitext-2

+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Model                                                       | Pre-trained Model                | Test Perplexity |Training Command                                                                                                                                                                                                                                                                                                                                                                    |
+=============================================================+==================================+=================+====================================================================================================================================================================================================================================================================================================================================================================================+
| Standard 2-layer LSTM language model (#hidden units = 200)  | standard_lstm_lm_200_wikitext-2  | 101.64          |python word_language_model.py --gpu 0 --emsize 200 --nhid 200 --nlayers 2 --lr 20 --epochs 750 --batch_size 20 --bptt 35 --dropout 0.2 --dropout_h 0 --dropout_i 0 --dropout_e 0 --weight_drop 0 --tied --wd 0 --alpha 0 --beta 0 --ntasgd --lr_update_interval 30 --lr_update_factor 0.1 â€”save standard_lstm_lm_200_wikitext-2                                                     |
+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Standard 2-layer LSTM language model (#hidden units = 650)  | standard_lstm_lm_650_wikitext-2  | 86.91           |python word_language_model.py --gpu 0 --emsize 650 --nhid 650 --nlayers 2 --lr 20 --epochs 750 --batch_size 20 --bptt 35 --dropout 0.5 --dropout_h 0 --dropout_i 0 --dropout_e 0 --weight_drop 0 --tied --wd 0 --alpha 0 --beta 0 --ntasgd --lr_update_interval 30 --lr_update_factor 0.1 --save standard_lstm_lm_650_wikitext-2                                                    |
+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Standard 2-layer LSTM language model (#hidden units = 1500) | standard_lstm_lm_1500_wikitext-2 | 82.29           |python word_language_model.py --gpu 0 --emsize 1500 --nhid 1500 --nlayers 2 --lr 20 --epochs 750 --batch_size 20 --bptt 35 --dropout 0.65 --dropout_h 0 --dropout_i 0 --dropout_e 0 --weight_drop 0 --tied --wd 0 --alpha 0 --beta 0 --ntasgd --lr_update_interval 30 --lr_update_factor 0.1 --save standard_lstm_lm_1500_wikitext-2                                                |
+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 3-layer AWD-LSTM language model (#hidden units = 600)       | awd_lstm_lm_600_wikitext-2       | 80.67           |python word_language_model.py --gpu 0 --emsize 200 --nhid 600 --epochs 750 --dropout 0.2 --dropout_h 0.1 --dropout_i 0.3 --dropout_e 0.05 --weight_drop 0.2 --tied --ntasgd --lr_update_interval 30 --lr_update_factor 0.1 --save awd_lstm_lm_600_wikitext-2                                                                                                                        |
+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 3-layer AWD-LSTM language model (#hidden units = 1150)      | awd_lstm_lm_1150_wikitext-2      | 65.62           |python word_language_model.py --gpu 0 --tied --ntasgd --lr_update_interval 30 --lr_update_factor 0.1 --save awd_lstm_lm_1150_wikitext-2                                                                                                                                                                                                                                             |
+-------------------------------------------------------------+----------------------------------+-----------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

