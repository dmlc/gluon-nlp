Model Catalog
=============




Language Model
--------------
`Language Model Model Zoo Index <./language_model/index.html>`_

Word Language Model
~~~~~~~~~~~~~~~~~~~

Dataset: Wikitext-2

+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+
| Pre-trained Model                     | Test Perplexity |Training Command                                                                                                             | log                                                                                                                         |
+=======================================+=================+=============================================================================================================================+=============================================================================================================================+
| standard_lstm_lm_200_wikitext-2  [1]_ | 101.64          |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_200_wikitext-2.sh>`__   |  `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_200_wikitext-2.log>`__    |
+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+
| standard_lstm_lm_650_wikitext-2  [1]_ | 86.91           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_650_wikitext-2.sh>`__   |  `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_650_wikitext-2.log>`__    |
+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+
| standard_lstm_lm_1500_wikitext-2 [1]_ | 82.29           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_1500_wikitext-2.sh>`__  |  `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/standard_lstm_lm_1500_wikitext-2.log>`__   |
+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+
| awd_lstm_lm_600_wikitext-2       [1]_ | 80.67           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/awd_lstm_lm_600_wikitext-2.sh>`__        |  `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/awd_lstm_lm_600_wikitext-2.log>`__         |
+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+
| awd_lstm_lm_1150_wikitext-2      [1]_ | 65.62           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/awd_lstm_lm_1150_wikitext-2.sh>`__       |  `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/awd_lstm_lm_1150_wikitext-2.log>`__        |
+---------------------------------------+-----------------+-----------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+


Cache Language Model
~~~~~~~~~~~~~~~~~~~~

Dataset: Wikitext-2

+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+
| Pre-trained Model                           | Test Perplexity |Training Command                                                                                                                  | log                                                                                                                           |
+=============================================+=================+==================================================================================================================================+===============================================================================================================================+
| cache_awd_lstm_lm_1150_wikitext-2      [2]_ | 51.46           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_awd_lstm_lm_1150_wikitext-2.sh>`__      |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_awd_lstm_lm_1150_wikitext-2.log>`__      |
+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+
| cache_awd_lstm_lm_600_wikitext-2       [2]_ | 62.19           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_awd_lstm_lm_600_wikitext-2.sh>`__       |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_awd_lstm_lm_600_wikitext-2.log>`__       |
+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+
| cache_standard_lstm_lm_1500_wikitext-2 [2]_ | 62.79           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_1500_wikitext-2.sh>`__ |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_1500_wikitext-2.log>`__ |
+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+
| cache_standard_lstm_lm_650_wikitext-2  [2]_ | 65.85           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_650_wikitext-2.sh>`__  |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_650_wikitext-2.log>`__  |
+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+
| cache_standard_lstm_lm_200_wikitext-2  [2]_ | 73.74           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_200_wikitext-2.sh>`__  |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/cache_standard_lstm_lm_200_wikitext-2.log>`__  |
+---------------------------------------------+-----------------+----------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+



Large Scale Word Language Model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dataset: Googleâ€™s 1 billion words dataset

+-------------------------+-----------------+-------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+
| Pre-trained Model       | Test Perplexity |Training Command                                                                                                   | log                                                                                                            |
+=========================+=================+===================================================================================================================+================================================================================================================+
| LSTM-2048-512      [3]_ | 43.62           |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/big_rnn_lm_2048_512_gbw.sh>`__ |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/language_model/big_rnn_lm_2048_512_gbw.log>`__ |
+-------------------------+-----------------+-------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+


Machine Translation
-------------------
`Machine Translation Model Zoo Index <./machine_translation/index.html>`_


Google Neural Machine Translation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dataset: IWLST2015-en-vi

+---------------------+-----------+-------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+
| Pre-trained Model   | Test BLEU |Training Command                                                                           | log                                                                                                            |
+=====================+===========+===========================================================================================+================================================================================================================+
| GNMT           [4]_ | 26.2      | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/nmt/gnmt.sh>`__      |                                                                                                                |
+---------------------+-----------+-------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+


Transformers
~~~~~~~~~~~~

Dataset: WMT14-en-de
Requisite: sacremoses package: pip install scaremoses --user

+------------------------------+-----------+-------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+
| Pre-trained Model            | Test BLEU |Training Command                                                                                                   | log                                                                                                            |
+==============================+===========+===================================================================================================================+================================================================================================================+
| transformer_en_de_512_WMT2014| 27.65     | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/nmt/transformer_en_de_u512.sh>`__            |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/nmt/transformer_en_de_u512.log>`__             |
+------------------------------+-----------+-------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+


Sentiment Analysis
------------------
`Sentiment Analysis Model Zoo Index <./sentiment_analysis/index.html>`_

Through Fine-tuning Word Language Model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dataset: IMDB

+------------------------------+---------------+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+
| Model                        | Test Accuracy |Training Command                                                                                                     | log                                                                                                              |
+==============================+===============+=====================================================================================================================+==================================================================================================================+
| lstm from scratch            | 85.60%        | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/sentiment_raw_20180817.sh>`__        | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/sentiment_raw_20180817.log>`__        |
+------------------------------+---------------+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+
| lstm with pre-trained model  | 86.46%        | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/sentiment_pretrained_20180817.sh>`__ | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/sentiment_pretrained_20180817.log>`__ |
+------------------------------+---------------+---------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------+

TextCNN
~~~~~~~

Dataset: MR

+--------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                    | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand        [5]_ | 75.80%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_rand.sh>`__                    | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_rand.log>`__                    |
+--------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static      [5]_ | 79.40%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_static.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_static.log>`__                  |
+--------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static  [5]_ | 80.00%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_non-static.sh>`__              | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_non-static.log>`__              |
+--------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
|TextCNN-multichannel [5]_ | 80.00%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_multichannel.sh>`__            | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MR_multichannel.log>`__            |
+--------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: Subj

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 89.30%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_rand.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_rand.log>`__                  |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 91.80%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_static.sh>`__                | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_static.log>`__                |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 91.90%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_non-static.sh>`__            | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_non-static.log>`__            |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 92.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_multichannel.sh>`__          | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/Subj_multichannel.log>`__          |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: CR

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 79.50%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_rand.sh>`__                    | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_rand.log>`__                    |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 83.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_static.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_static.log>`__                  |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 82.90%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_non-static.sh>`__              | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_non-static.log>`__              |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 83.30%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_multichannel.sh>`__            | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/CR_multichannel.log>`__            |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: MPQA

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 85.30%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_rand.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_rand.log>`__                  |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 89.60%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_static.sh>`__                | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_static.log>`__                |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 89.20%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_non-static.sh>`__            | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_non-static.log>`__            |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 89.60%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_multichannel.sh>`__          | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/MPQA_multichannel.log>`__          |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: SST-1

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 44.30%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_rand.sh>`__                 | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_rand.log>`__                 |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 48.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_static.sh>`__               | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_static.log>`__               |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 47.00%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_non-static.sh>`__           | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_non-static.log>`__           |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 48.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_multichannel.sh>`__         | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-1_multichannel.log>`__         |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: SST-2

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 82.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_rand.sh>`__                 | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_rand.log>`__                 |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 87.10%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_static.sh>`__               | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_static.log>`__               |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 85.60%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_non-static.sh>`__           | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_non-static.log>`__           |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 85.80%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_multichannel.sh>`__         | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/SST-2_multichannel.log>`__         |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: TREC

+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Model                     | Cross-Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+===========================+===========================+==================================================================================================================+===============================================================================================================+
| TextCNN-rand         [5]_ | 90.20%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_rand.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_rand.log>`__                  |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-static       [5]_ | 91.40%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_static.sh>`__                | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_static.log>`__                |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-non-static   [5]_ | 93.20%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_non-static.sh>`__            | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_non-static.log>`__            |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| TextCNN-multichannel [5]_ | 93.20%                    | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_multichannel.sh>`__          | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/sentiment/TREC_multichannel.log>`__          |
+---------------------------+---------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Finetuning
----------
`BERT Model Zoo Index <./bert/index.html>`_

Task: Sentence Classification
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dataset: MRPC

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 88.70%              | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_mrpc.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_mrpc.log>`__                  |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: RTE

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 70.80%              | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_rte.sh>`__                   | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_rte.log>`__                   |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: SST-2

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 93%                 | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_sst.sh>`__                   | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_sst.log>`__                   |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| RoBERTa-base     | 95.3%               | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/roberta/finetuned_sst.sh>`__                | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/roberta/finetuned_sst.log>`__                |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+


Dataset: MNLI-M/MM

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 84.55%/84.66%       | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_mnli.sh>`__                  | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_mnli.log>`__                  |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| RoBERTa-base     | 87.69%/87.23%       | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/roberta/finetuned_mnli.sh>`__               | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/roberta/mnli_1e-5-32.log>`__                 |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset: XNLI(Chinese)

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | Validation Accuracy | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 78.27%              | `command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_XNLI-B_base_mx1.6.0rc1.sh>`__ | `log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_xnli.log>`__                  |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Task: Question Answering
~~~~~~~~~~~~~~~~~~~~~~~~

Dataset: SQuAD 1.1

+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Pretrained Model | F1/EM               | Training Command                                                                                                   | Log                                                                                                             |
+==================+=====================+====================================================================================================================+=================================================================================================================+
| BERT-base        | 88.53%/80.98%       |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad1.1_base_mx1.6.0rc1.sh>`__  |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad1.1_base_mx1.6.0rc1.log>`__  |
+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| BERT-large       | 90.97%/84.05%       |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad1.1_large_mx1.6.0rc1.sh>`__ |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad1.1_large_mx1.6.0rc1.log>`__ |
+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+

Dataset: SQuAD 2.0

+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Pretrained Model | F1/EM               | Training Command                                                                                                   | Log                                                                                                             |
+==================+=====================+====================================================================================================================+=================================================================================================================+
| BERT-large       | 77.96%/81.02%       |`command <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad2.0_large_mx1.6.0rc1.sh>`__ |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetune_squad2.0_large_mx1.6.0rc1.log>`__ |
+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+

Task: Named Entity Recognition
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Requisite: python3 and seqeval package: pip3 install seqeval --user

Dataset:  CoNLL-2003

+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+
| Pretrained Model | F1                  | Training Command                                                                                                   | Log                                                                                                             |
+==================+=====================+====================================================================================================================+=================================================================================================================+
| BERT-large       | 92.20%              |                                                                                                                    |`log <https://github.com/dmlc/web-data/blob/master/gluonnlp/logs/bert/finetuned_conll2003.log>`__                |
+------------------+---------------------+--------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------+

Task: Joint Intent Classification and Slot Labelling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Requisite: python3 and seqeval & tqdm packages: pip3 install seqeval --user and pip3 install tqdm --user

Dataset:  ATIS

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | F1/Accuracy         | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 95.83%/98.66%       |                                                                                                                  |                                                                                                               |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+

Dataset:  SNIPS

+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+
| Pretrained Model | F1/Accuracy         | Training Command                                                                                                 | Log                                                                                                           |
+==================+=====================+==================================================================================================================+===============================================================================================================+
| BERT-base        | 96.06%/98.71%       |                                                                                                                  |                                                                                                               |
+------------------+---------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------+




.. [1] Merity, S., et al.  \
       "`Regularizing and optimizing LSTM language models <https://openreview.net/pdf?id=SyyGPP0TZ>`_". \
       ICLR 2018
.. [2] Grave, E., et al. \
       "`Improving neural language models with a continuous cache <https://openreview.net/pdf?id=B184E5qee>`_".\
       ICLR 2017
.. [3] Jozefowicz, Rafal, et al. \
       "`Exploring the limits of language modeling <https://arxiv.org/abs/1602.02410>`_".\
       arXiv preprint arXiv:1602.02410 (2016).
.. [4] Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., ... & Klingner, J. (2016). \
       "`Google's neural machine translation system: Bridging the gap between human and machine translation. <https://arxiv.org/abs/1609.08144>`_". \
       arXiv preprint arXiv:1609.08144.
.. [5] Kim, Y. (2014). \
       "`Convolutional neural networks for sentence classification <https://arxiv.org/abs/1408.5882>`_". \
       arXiv preprint arXiv:1408.5882.
